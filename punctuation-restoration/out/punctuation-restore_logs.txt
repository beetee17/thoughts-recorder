Namespace(alpha_del=0.4, alpha_sub=0.4, augment_rate=0.15, augment_type='all', batch_size=8, cuda=True, data_path='data', decay=0, epoch=10, freeze_bert=False, gradient_clip=-1, language='english', lr=5e-06, lstm_dim=-1, name='punctuation-restore', pretrained_model='distilbert-base-uncased', save_path='out', seed=1, sequence_length=256, sub_style='unk', use_crf=False)
epoch: 0, Train loss: 0.3311812660670893, Train accuracy: 0.8803444474420211
epoch: 0, Val loss: 0.21890796544030308, Val accuracy: 0.9090851197897813
Namespace(alpha_del=0.4, alpha_sub=0.4, augment_rate=0.15, augment_type='all', batch_size=8, cuda=True, data_path='data', decay=0, epoch=10, freeze_bert=False, gradient_clip=-1, language='english', lr=5e-06, lstm_dim=-1, name='punctuation-restore', pretrained_model='distilbert-base-uncased', save_path='out', seed=1, sequence_length=256, sub_style='unk', use_crf=False)
epoch: 0, Train loss: 0.3311812660670893, Train accuracy: 0.8803444474420211
epoch: 0, Val loss: 0.21890796544030308, Val accuracy: 0.9090851197897813
Namespace(alpha_del=0.4, alpha_sub=0.4, augment_rate=0.15, augment_type='all', batch_size=8, cuda=True, data_path='data', decay=0, epoch=10, freeze_bert=False, gradient_clip=-1, language='english', lr=5e-06, lstm_dim=-1, name='punctuation-restore', pretrained_model='albert-base-v2', save_path='out', seed=1, sequence_length=256, sub_style='unk', use_crf=False)
Namespace(alpha_del=0.4, alpha_sub=0.4, augment_rate=0.15, augment_type='all', batch_size=8, cuda=True, data_path='data', decay=0, epoch=1, freeze_bert=False, gradient_clip=-1, language='english', lr=5e-06, lstm_dim=-1, name='punctuation-restore', pretrained_model='albert-base-v2', save_path='out', seed=1, sequence_length=256, sub_style='unk', use_crf=False)
epoch: 0, Train loss: 0.28334594087610987, Train accuracy: 0.8939696941357071
epoch: 0, Val loss: 0.17086890258572318, Val accuracy: 0.9322521194249908
Precision: [0.97096734 0.6409587  0.71524894        nan 0.67933767]
Recall: [0.98335368 0.54674625 0.77414067 0.         0.62768786]
F1 score: [0.97712126 0.59011586 0.74353049        nan 0.65249224]
Accuracy:0.9322521194249908
Confusion Matrix[[251298   3380    874      0]
 [  6214  12275   3962      0]
 [  1154   3117  14639      0]
 [   146    379    992      0]]
64.09586966738028 54.67462473831901 59.011585981443204 71.52489373137246 77.41406663141194 74.35304873403254 nan 0.0 nan 67.93376747942854 62.768785857549325 65.24922420480993

Precision: [0.97727069 0.64945652 0.75774971        nan 0.70815184]
Recall: [0.98398915 0.57590361 0.81784387 0.         0.6761735 ]
F1 score: [0.98061841 0.61047254 0.78665077        nan 0.69179331]
Accuracy:0.9433192023865599
Confusion Matrix[[10878   150    27     0]
 [  199   478   153     0]
 [   50    97   660     0]
 [    4    11    31     0]]
64.94565217391305 57.59036144578313 61.04725415070242 75.77497129735936 81.78438661710037 78.66507747318236 nan 0.0 nan 70.81518357187305 67.61734997029116 69.17933130699087

Precision: [0.97565124 0.49021739 0.72716489        nan 0.60351673]
Recall: [0.9651966  0.56516291 0.75772559 0.         0.64799026]
F1 score: [0.97039576 0.5250291  0.74213075        nan 0.62496329]
Accuracy:0.9249265501778259
Confusion Matrix[[10899   329    64     0]
 [  202   451   145     0]
 [   63   133   613     0]
 [    7     7    21     0]]
49.02173913043478 56.51629072681704 52.50291036088475 72.71648873072361 75.7725587144623 74.21307506053269 nan 0.0 nan 60.3516732841747 64.79902557856273 62.49632892804699

Namespace(alpha_del=0.4, alpha_sub=0.4, augment_rate=0.15, augment_type='all\xa0', batch_size=8, cuda=True, data_path='data', decay=0, epoch=5, freeze_bert=False, gradient_clip=-1, language='english', lr=5e-06, lstm_dim=-1, name='punctuation-restore', pretrained_model='albert-base-v2', save_path='out', seed=1, sequence_length=256, sub_style='unk', use_crf=False)
Namespace(alpha_del=0.4, alpha_sub=0.4, augment_rate=0.15, augment_type='all\xa0', batch_size=8, cuda=True, data_path='data', decay=0, epoch=5, freeze_bert=False, gradient_clip=-1, language='english', lr=5e-06, lstm_dim=-1, name='punctuation-restore', pretrained_model='albert-base-v2', save_path='out', seed=1, sequence_length=256, sub_style='unk', use_crf=False)
Namespace(alpha_del=0.4, alpha_sub=0.4, augment_rate=0.15, augment_type='all\xa0', batch_size=8, cuda=True, data_path='data', decay=0, epoch=5, freeze_bert=False, gradient_clip=-1, language='english', lr=5e-06, lstm_dim=-1, name='punctuation-restore', pretrained_model='albert-base-v2', save_path='out', seed=1, sequence_length=256, sub_style='unk', use_crf=False)
epoch: 0, Train loss: 0.28334594087610987, Train accuracy: 0.8939696941357071
epoch: 0, Val loss: 0.17086890258572318, Val accuracy: 0.9322521194249908
epoch: 1, Train loss: 0.18924885347228626, Train accuracy: 0.9207495029281697
epoch: 1, Val loss: 0.14570733439741712, Val accuracy: 0.93984518982676
epoch: 2, Train loss: 0.16725293710699368, Train accuracy: 0.9292562396804958
epoch: 2, Val loss: 0.13536043532870032, Val accuracy: 0.9432932345943772
epoch: 3, Train loss: 0.1584819439092073, Train accuracy: 0.932704651746379
epoch: 3, Val loss: 0.13039392278049933, Val accuracy: 0.9452702476292598
epoch: 4, Train loss: 0.15284544358608024, Train accuracy: 0.9347198562799054
epoch: 4, Val loss: 0.12540543282573874, Val accuracy: 0.9467010689273867
Precision: [0.97932194 0.71326511 0.7834379  0.76788321 0.74845855]
Recall: [0.98204279 0.6581444  0.83199365 0.69347396 0.73606511]
F1 score: [0.98068048 0.68459703 0.80698605 0.72878421 0.7422101 ]
Accuracy:0.9467010689273867
Confusion Matrix[[250963   3665    837     87]
 [  4235  14776   3296    144]
 [   938   2152  15733     87]
 [   126    123    216   1052]]
71.32651090944198 65.81444033673333 68.45970301387634 78.34379045911761 83.19936541512428 80.69860484201887 76.78832116788321 69.34739617666446 72.87842050571528 74.84585467653197 73.60651149773777 74.22100980645769

Precision: [0.98474114 0.68606061 0.8147714  0.68       0.7494213 ]
Recall: [0.9807327  0.68192771 0.86121437 0.73913043 0.7694593 ]
F1 score: [0.98273283 0.68398792 0.8373494  0.70833333 0.75930812]
Accuracy:0.9528183388287015
Confusion Matrix[[10842   183    28     2]
 [  130   566   125     9]
 [   36    71   695     5]
 [    2     5     5    34]]
68.60606060606061 68.19277108433735 68.3987915407855 81.47713950762017 86.12143742255266 83.73493975903614 68.0 73.91304347826086 70.83333333333334 74.94212962962963 76.94592988710636 75.93081207856935

Precision: [0.98020337 0.55605889 0.7300885  0.55882353 0.64250412]
Recall: [0.96466525 0.61528822 0.815822   0.54285714 0.71254568]
F1 score: [0.97237224 0.58417609 0.77057793 0.55072464 0.6757147 ]
Accuracy:0.9326581104066801
Confusion Matrix[[10893   312    81     6]
 [  151   491   154     2]
 [   64    78   660     7]
 [    5     2     9    19]]
55.60588901472253 61.528822055137844 58.41760856632956 73.00884955752213 81.58220024721878 77.05779334500875 55.88235294117647 54.285714285714285 55.07246376811593 64.2504118616145 71.2545676004872 67.57146982385215

Namespace(alpha_del=0.4, alpha_sub=0.4, augment_rate=0.15, augment_type='all\xa0', batch_size=8, cuda=True, data_path='data', decay=0, epoch=5, freeze_bert=False, gradient_clip=-1, language='english', lr=5e-06, lstm_dim=-1, name='punctuation-restore', pretrained_model='albert-base-v2', save_path='out', seed=1, sequence_length=256, sub_style='unk', use_crf=False)
epoch: 0, Train loss: 0.14855662942061137, Train accuracy: 0.9364920072898439
epoch: 0, Val loss: 0.12449987173983545, Val accuracy: 0.9471467345776229
Namespace(alpha_del=0.4, alpha_sub=0.4, augment_rate=0.15, augment_type='all\xa0', batch_size=8, cuda=True, data_path='data', decay=0, epoch=5, freeze_bert=False, gradient_clip=-1, language='english', lr=5e-06, lstm_dim=-1, name='punctuation-restore', pretrained_model='albert-base-v2', save_path='out', seed=1, sequence_length=256, sub_style='unk', use_crf=False)
Namespace(alpha_del=0.4, alpha_sub=0.4, augment_rate=0.15, augment_type='all\xa0', batch_size=8, cuda=True, data_path='data', decay=0, epoch=10, freeze_bert=False, gradient_clip=-1, language='english', lr=5e-06, lstm_dim=-1, name='punctuation-restore', pretrained_model='albert-base-v2', save_path='out', seed=1, sequence_length=256, sub_style='unk', use_crf=False)
epoch: 0, Train loss: 0.5900866147002269, Train accuracy: 0.8291344691288869
epoch: 0, Val loss: 0.4920690885095885, Val accuracy: 0.8563214154072982
epoch: 1, Train loss: 0.46544542284361246, Train accuracy: 0.8629879152439237
epoch: 1, Val loss: 0.4878904644286994, Val accuracy: 0.8563214154072982
epoch: 2, Train loss: 0.4635098232020592, Train accuracy: 0.8630185316123942
epoch: 2, Val loss: 0.48738783742442277, Val accuracy: 0.8563214154072982
epoch: 3, Train loss: 0.46336212553854644, Train accuracy: 0.8630539275482096
epoch: 3, Val loss: 0.48688083652294045, Val accuracy: 0.8563214154072982
Namespace(alpha_del=0.4, alpha_sub=0.4, augment_rate=0.15, augment_type='all\xa0', batch_size=8, cuda=True, data_path='data', decay=0, epoch=10, freeze_bert=False, gradient_clip=-1, language='english', lr=5e-06, lstm_dim=-1, name='punctuation-restore', pretrained_model='albert-base-v2', save_path='out', seed=1, sequence_length=256, sub_style='unk', use_crf=False)
epoch: 0, Train loss: 0.5952906861901284, Train accuracy: 0.8264097421467244
epoch: 0, Val loss: 0.4925634306488615, Val accuracy: 0.8563214154072982
Namespace(alpha_del=0.4, alpha_sub=0.4, augment_rate=0.15, augment_type='all\xa0', batch_size=8, cuda=True, data_path='data', decay=0, epoch=10, freeze_bert=False, gradient_clip=-1, language='english', lr=5e-06, lstm_dim=-1, name='punctuation-restore', pretrained_model='albert-base-v2', save_path='out', seed=10, sequence_length=256, sub_style='unk', use_crf=False)
Namespace(alpha_del=0.4, alpha_sub=0.4, augment_rate=0.15, augment_type='all\xa0', batch_size=8, cuda=True, data_path='data', decay=0, epoch=10, freeze_bert=False, gradient_clip=-1, language='english', lr=5e-06, lstm_dim=-1, name='punctuation-restore', pretrained_model='albert-base-v2', save_path='out', seed=10, sequence_length=256, sub_style='unk', use_crf=False)
epoch: 0, Train loss: 2.3976244926452637, Train accuracy: 0.0
epoch: 0, Val loss: 2.332391088956023, Val accuracy: 0.005807108897441703
Namespace(alpha_del=0.4, alpha_sub=0.4, augment_rate=0.15, augment_type='all\xa0', batch_size=8, cuda=True, data_path='data', decay=0, epoch=10, freeze_bert=False, gradient_clip=-1, language='english', lr=5e-06, lstm_dim=-1, name='punctuation-restore', pretrained_model='albert-base-v2', save_path='out', seed=10, sequence_length=256, sub_style='unk', use_crf=False)
Namespace(alpha_del=0.4, alpha_sub=0.4, augment_rate=0.15, augment_type='all\xa0', batch_size=64, cuda=True, data_path='data', decay=0, epoch=10, freeze_bert=False, gradient_clip=-1, language='english', lr=5e-06, lstm_dim=-1, name='punctuation-restore', pretrained_model='albert-base-v2', save_path='out', seed=10, sequence_length=256, sub_style='unk', use_crf=False)
Namespace(alpha_del=0.4, alpha_sub=0.4, augment_rate=0.15, augment_type='all\xa0', batch_size=8, cuda=True, data_path='data', decay=0, epoch=10, freeze_bert=False, gradient_clip=-1, language='english', lr=5e-06, lstm_dim=-1, name='punctuation-restore', pretrained_model='albert-base-v2', save_path='out', seed=10, sequence_length=256, sub_style='unk', use_crf=False)
Namespace(alpha_del=0.4, alpha_sub=0.4, augment_rate=0.15, augment_type='all\xa0', batch_size=8, cuda=True, data_path='data', decay=0, epoch=10, freeze_bert=False, gradient_clip=-1, language='english', lr=5e-06, lstm_dim=-1, name='punctuation-restore', pretrained_model='albert-base-v2', save_path='out', seed=10, sequence_length=256, sub_style='unk', use_crf=False)
Namespace(alpha_del=0.4, alpha_sub=0.4, augment_rate=0.15, augment_type='all\xa0', batch_size=8, cuda=True, data_path='data', decay=0, epoch=10, freeze_bert=False, gradient_clip=-1, language='english', lr=5e-06, lstm_dim=-1, name='punctuation-restore', pretrained_model='albert-base-v2', save_path='out', seed=10, sequence_length=256, sub_style='unk', use_crf=False)
epoch: 0, Train loss: 0.3579824600557151, Train accuracy: 0.8665354484793569
epoch: 0, Val loss: 0.19008830661260628, Val accuracy: 0.9259364519979537
epoch: 1, Train loss: 0.2402870067078769, Train accuracy: 0.9012038695938102
epoch: 1, Val loss: 0.16575098933675622, Val accuracy: 0.9338045951471746
epoch: 2, Train loss: 0.22205066985013533, Train accuracy: 0.9078725519151403
epoch: 2, Val loss: 0.15507935730245295, Val accuracy: 0.9369187814023828
epoch: 3, Train loss: 0.2121378299365626, Train accuracy: 0.9117201155780688
epoch: 3, Val loss: 0.15032488927009363, Val accuracy: 0.9382657358556864
epoch: 4, Train loss: 0.20503372737145642, Train accuracy: 0.9143039657316249
epoch: 4, Val loss: 0.14941297459734393, Val accuracy: 0.9388272539525879
epoch: 5, Train loss: 0.19979200832362853, Train accuracy: 0.9163304301075978
epoch: 5, Val loss: 0.14637609050149405, Val accuracy: 0.9402723879504418
epoch: 6, Train loss: 0.19523511428569978, Train accuracy: 0.9181360276369083
epoch: 6, Val loss: 0.14616323043179663, Val accuracy: 0.9405669265840925
epoch: 7, Train loss: 0.19088601478984532, Train accuracy: 0.9199334198610932
epoch: 7, Val loss: 0.14181188854707194, Val accuracy: 0.9415263302036451
epoch: 8, Train loss: 0.18776594398995541, Train accuracy: 0.9210781897285617
epoch: 8, Val loss: 0.1406337843524127, Val accuracy: 0.9417640280483457
epoch: 9, Train loss: 0.18546339078384616, Train accuracy: 0.9220403518059763
epoch: 9, Val loss: 0.139793184951325, Val accuracy: 0.9422239217043968
Precision: [0.96997054 0.78358763 0.83169842 0.79890881 0.87858832 0.76660498
 0.72934473 0.69387755 0.83371256]
Recall: [0.97973941 0.69696151 0.84874782 0.82263242 0.86279182 0.68265885
 0.71977507 0.45333333 0.8024228 ]
F1 score: [0.9748305  0.73774035 0.84013663 0.81059707 0.87061842 0.7222007
 0.7245283  0.5483871  0.81776849]
Accuracy:0.9422239217043968
Confusion Matrix[[448462   3240    984     90   4882     66     11      1]
 [  5992  23213   3572    207     82    207     30      3]
 [  1286   2740  24842    167     33     77    120      4]
 [   133    115    160   2050      8      8      6     12]
 [  6201     41     40      6  43093    501     61      3]
 [   221    228     83      8    870   3728    312     11]
 [    46     42    174      5     72    248   1536     11]
 [     5      5     14     33      8     28     30    102]]
78.35876316500135 69.69615084369183 73.77403464166535 83.16984164183602 84.87478219276367 84.01366295782745 79.89088074824629 82.26324237560193 81.05970739422698 87.85883216441037 86.27918151603731 87.06184213184636

Precision: [0.97079366 0.78580493 0.82527255 0.83544947 0.87515687 0.7687747
 0.69447709 0.68548387 0.83162861]
Recall: [0.97836743 0.69777743 0.86499603 0.79583938 0.86710877 0.67184801
 0.71290712 0.43814433 0.80726913]
F1 score: [0.97456583 0.73917965 0.84466751 0.81516353 0.87111423 0.71705069
 0.70357143 0.53459119 0.81926784]
Accuracy:0.9423808986002139
Confusion Matrix[[348878   2808    894     64   3885     48     13      2]
 [  4614  17958   2796    123     66    149     28      2]
 [   969   1774  19606     99     48     57    112      1]
 [   117    106    166   1645      2     13      2     16]
 [  4604     37     49      4  33473    346     88      2]
 [   140    148     70      7    705   2723    250     10]
 [    45     13    168      6     55    183   1182      6]
 [     7      9      8     21     14     23     27     85]]
78.58049271430447 69.7777432390426 73.9179649714956 82.52725512480532 86.49960292949793 84.46675139478276 83.54494667343829 79.58393807450412 81.51635282457879 87.51568709475005 86.71087739294873 87.11142340372928

Namespace(alpha_del=0.4, alpha_sub=0.4, augment_rate=0.15, augment_type='all\xa0', batch_size=8, cuda=True, data_path='data', decay=0, epoch=5, freeze_bert=False, gradient_clip=-1, language='english', lr=5e-06, lstm_dim=-1, name='punctuation-restore', pretrained_model='albert-base-v2', save_path='out', seed=10, sequence_length=256, sub_style='unk', use_crf=False)
epoch: 0, Train loss: 0.18156928155891855, Train accuracy: 0.9237938735011096
epoch: 0, Val loss: 0.14084691174705571, Val accuracy: 0.9419948361004463
epoch: 1, Train loss: 0.17791829829172282, Train accuracy: 0.9251610610854062
epoch: 1, Val loss: 0.1412080841822715, Val accuracy: 0.942279040045197
epoch: 2, Train loss: 0.17559414709312468, Train accuracy: 0.9260764259937989
epoch: 2, Val loss: 0.14040665253053738, Val accuracy: 0.9424736766861476
epoch: 3, Train loss: 0.17351307522938542, Train accuracy: 0.9270596756996714
epoch: 3, Val loss: 0.1399758373729036, Val accuracy: 0.942630419467798
epoch: 4, Train loss: 0.1709910066116847, Train accuracy: 0.9280235667726602
epoch: 4, Val loss: 0.1423016323036031, Val accuracy: 0.9420465095449464
Precision: [0.97021405 0.77670383 0.83949608 0.81566265 0.878083   0.77687886
 0.75795229 0.63583815 0.83477253]
Recall: [0.97995569 0.70692968 0.84239298 0.81500803 0.8646338  0.66819264
 0.71462043 0.48888889 0.80353814]
F1 score: [0.97506054 0.74017605 0.84094204 0.81533521 0.87130651 0.71844851
 0.73564882 0.55276382 0.81885759]
Accuracy:0.942630419467798
Confusion Matrix[[448561   3389    835     65   4823     50     10      3]
 [  5866  23545   3439    177     81    168     29      1]
 [  1344   2891  24656    158     39     74    104      3]
 [   141    145    149   2031      6      7      2     11]
 [  6160     51     38      7  43185    457     44      4]
 [   214    247     74     10    964   3649    277     26]
 [    38     39    168      4     76    269   1525     15]
 [     8      7     11     38      7     23     21    110]]
77.67038332123771 70.69296823395183 74.01760452687833 83.94960844399047 84.2392975503092 84.09420351643104 81.56626506024097 81.5008025682183 81.53352067442793 87.80829995323397 86.46338045088696 87.13065057955956

Precision: [0.97085058 0.77701405 0.83269734 0.85684431 0.87565065 0.77445339
 0.71132765 0.64705882 0.83223181]
Recall: [0.97856093 0.7071806  0.85683402 0.79342042 0.86721239 0.66419936
 0.70446321 0.45360825 0.80741653]
F1 score: [0.97469051 0.74045444 0.84459327 0.82391359 0.87141109 0.71510161
 0.70787879 0.53333333 0.81963639]
Accuracy:0.9425647021828336
Confusion Matrix[[348947   2971    748     54   3812     42     16      2]
 [  4474  18200   2746     98     69    133     15      1]
 [  1053   1879  19421     87     49     64    112      1]
 [   126    124    142   1640      6      9      4     16]
 [  4650     44     27      3  33477    332     68      2]
 [   127    177     60      6    741   2692    236     14]
 [    42     18    170      4     62    182   1168     12]
 [     5     10      9     22     15     22     23     88]]
77.70140460231396 70.71806030463165 74.04544437437704 83.26973373922738 85.68340245301333 84.45932723042468 85.68443051201672 79.34204160619255 82.39135895503642 87.56506499960764 86.72123928192109 87.14110940469062

Namespace(alpha_del=0.4, alpha_sub=0.4, augment_rate=0.15, augment_type='all\xa0', batch_size=8, cuda=True, data_path='data', decay=0, epoch=3, freeze_bert=False, gradient_clip=-1, language='english', lr=5e-06, lstm_dim=-1, name='punctuation-restore', pretrained_model='albert-base-v2', save_path='out', seed=10, sequence_length=256, sub_style='unk', use_crf=False)
epoch: 0, Train loss: 0.18156928155891855, Train accuracy: 0.9237938735011096
epoch: 0, Val loss: 0.14084691174705571, Val accuracy: 0.9419948361004463
epoch: 1, Train loss: 0.17791829829172282, Train accuracy: 0.9251610610854062
epoch: 1, Val loss: 0.1412080841822715, Val accuracy: 0.942279040045197
epoch: 2, Train loss: 0.17559414709312468, Train accuracy: 0.9260764259937989
epoch: 2, Val loss: 0.14040665253053738, Val accuracy: 0.9424736766861476
Precision: [0.96961846 0.7945114  0.82538903 0.82141414 0.87886934 0.76365482
 0.73497397 0.70779221 0.83578617]
Recall: [0.98037515 0.67888669 0.86080836 0.81581059 0.86405318 0.6887017
 0.72774133 0.48444444 0.8012342 ]
F1 score: [0.97496714 0.73216223 0.84272669 0.81860278 0.87139828 0.72424417
 0.73133977 0.57519789 0.81814554]
Accuracy:0.9424736766861476
Confusion Matrix[[448753   2995    986     66   4864     61      8      3]
 [  6289  22611   3882    188     85    222     28      1]
 [  1242   2447  25195    133     34     82    133      3]
 [   144    122    163   2033      5      7      5     13]
 [  6136     33     44      8  43156    516     51      2]
 [   207    208     83      8    872   3761    310     12]
 [    37     37    160      5     81    250   1553     11]
 [     6      6     12     34      7     26     25    109]]
79.45114023683193 67.88866870834084 73.21622277989151 82.53890253890253 86.08083637978748 84.27266949861189 82.14141414141413 81.58105939004815 81.86027783370243 87.88693385467579 86.40531774316261 87.13982836951033

Precision: [0.97049454 0.79594973 0.82038412 0.85260417 0.87636449 0.7641068
 0.69965278 0.6953125  0.83378521]
Recall: [0.97903486 0.68417781 0.87254037 0.79196904 0.8672383  0.68492475
 0.7291918  0.45876289 0.8062373 ]
F1 score: [0.97474599 0.73584354 0.84565882 0.8211688  0.87177751 0.72235233
 0.71411695 0.55279503 0.81977989]
Accuracy:0.9426909287395725
Confusion Matrix[[349116   2618    865     62   3851     65     13      2]
 [  4737  17608   3026    114     69    151     30      1]
 [   985   1603  19777     75     39     59    127      1]
 [   121    108    164   1637      5     12      3     17]
 [  4600     30     47      3  33478    376     67      2]
 [   124    137     70      5    682   2776    250      9]
 [    40     10    151      4     64    173   1209      7]
 [     7      8      7     20     13     21     29     89]]
79.59497332971702 68.41778054087659 73.58435371306783 82.038412079479 87.25403688343775 84.56588202595515 85.26041666666667 79.19690372520562 82.11687985954353 87.63644930760975 86.72382975416419 87.17775115879381

